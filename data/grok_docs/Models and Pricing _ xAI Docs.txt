Documentation	Cookbook



Getting Started
Models and Pricing
An overview of our models' capabilities and their associated pricing. Our Grok 3 models come in two variants: a fast and a standard version (details here).








Model Pricing


ModelInputOutputContextPrice	Per Million Tokens
grok-3-beta
grok-3
grok-3-latest





131072
 Text Input		$3.00  Text Completion	$15.00
grok-3-fast-beta
grok-3-fast
grok-3-fast-latest





131072
 Text Input		$5.00  Text Completion	$25.00
grok-3-mini-beta
grok-3-mini
grok-3-mini-latest





131072
 Text Input	$0.30
 Text Completion	$0.50
grok-3-mini-fast-beta
grok-3-mini-fast
grok-3-mini-fast-latest





131072
 Text Input	$0.60
 Text Completion	$4.00
grok-2-vision-1212
grok-2-vision
grok-2-vision-latest

 



8192
 Text Input	$2.00
 Image Input		$2.00  Text Completion	$10.00
grok-2-image-1212
grok-2-image
grok-2-image-latest





131072

Each Generated Image	$0.07


Show legacy models



What is the difference between grok-3 and grok-3-fast?


Both


grok-3

and


grok-3-fast

use the exact same underlying model and deliver identical response

quality. The difference lies in how they're served:


grok-3-fast

is served on faster infrastructure,

offering response times that are significantly faster than the standard comes at a higher cost per output token.

grok-3 . The increased speed





The same can be said for


grok-3-mini

and

grok-3-mini-fast . Under the hood, both are identical

models that differ only in response latency.




Additional Information Regarding Models


No access to realtime events

Unlike grok.com and Grok in X, the Grok models on the xAI API are not connected to the internet.
Grok has no knowledge of current events or data beyond what was present in its training data. Please pass any realtime data as context in your system prompt.
Chat models


No role order limitation: You can mix for your conversation context.


system ,


user , or


assistant


roles in any sequence

Image input models


Maximum image size:


10MiB

Maximum number of images: No limit

Supported image file types:


jpg/jpeg

or png .

Any image/text input order is accepted (e.g. text prompt can precede image prompt)




Model Aliases

Some models have aliases to help user automatically migrate to the next version of the same model. In general:


<modelname>


is aliased to the latest stable version.


<modelname>-latest

is aliased to the latest version. This is suitable for users who want to

access the latest features.


<modelname>-<date>

refers directly to a specific model release. This will not be updated and is

for workflows that demand consistency.


For most users, the aliased

<modelname> or


<modelname>-latest

are recommended, as you would

receive the latest features automatically.



Billing and Availability

Your model access might vary depending on various factors such as geographical location, account limitations, etc.

For how the bills are charged, visit Billing for more information.

For the most up-to-date information on your team's model availability, visit Models Page on xAI Console.




Model Input and Output

Each model can have one or multiple input and output capabilities. The input capabilities refer to which type(s) of prompt can the model accept in the request message body. The output capabilities refer to which type(s) of completion will the model generate in the response message body.


This is a prompt example for models with


text


input capability:





This is a prompt example for models with


text

and


image

input capabilities:





This is a prompt example for models with


text

input and


image

output capabilities:









Context Window

The context window determines the maximum amount of token accepted by the model in the prompt.

For more information on how token is counted, visit Consumption and Rate Limits.

If you are sending the entire conversation history in the prompt for use cases like chat assistant, the sum of all the prompts in your conversation history must be no greater than the context window.
